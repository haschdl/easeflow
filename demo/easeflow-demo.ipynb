{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ðŸ“˜ Easing Functions & Perlin Noise\n",
    "Easing functions control how values transition over time, making animations and data curves **smooth and natural**. Perlin noise adds **realistic variations**, commonly used in **graphics, simulations, and time-series generation**.\n",
    "\n",
    "### ðŸ”¹ What Are Easing Functions?\n",
    "Instead of moving at a constant speed, easing functions create **acceleration and deceleration effects**. Examples:\n",
    "- **CubicEaseInOut** â†’ Smooth start & end  \n",
    "- **QuadEaseIn** â†’ Slow start, fast finish  \n",
    "- **CircularEaseIn** â†’ Simulates circular motion  \n",
    "\n",
    "### ðŸ”¹ Why Use Perlin Noise?\n",
    "Perlin noise introduces **fluid randomness**, making transitions **less artificial**. Itâ€™s great for **terrain generation, animations, and synthetic data**.\n",
    "\n",
    "### ðŸ“Œ What This Notebook Covers\n",
    "âœ… Visualizing easing functions (**Matplotlib**)  \n",
    "âœ… Adding Perlin noise for realistic variation  \n",
    "âœ… Generating synthetic data with **`easeflow`** (PySpark)  \n",
    "\n",
    "ðŸ‘‰ **Run the next cells to explore these concepts interactively!** ðŸš€  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Easing Functions & Perlin Noise (Matplotlib)\n",
    "\n",
    " > Skip this section if you are familiar with both Easing functions and Perlin noise. \n",
    "\n",
    "Before diving in the simplified approach the `easeflow` provided, let's check a simple example using Matplot lib and numpy.\n",
    "\n",
    "In the next cell, we will visualize various easing functions and see how Perlin noise can be applied to them. This will help us understand the impact of noise on smooth transitions and how it can make animations and synthetic data more dynamic and realistic.\n",
    "\n",
    "We will use interactive widgets to adjust the noise parameters and observe the changes in real-time. This interactive approach allows for a deeper exploration of how different easing functions behave under the influence of Perlin noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a360f6759b4e25a5a0cebbb5040ecb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(FloatSlider(value=0.3, description='Noise Max', max=5.0), FloatSlider(value=2.0, descripâ€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from ipywidgets import interact, FloatSlider\n",
    "from perlin_noise import PerlinNoise\n",
    "import easing_functions as easy\n",
    "from pyspark.sql.functions import lit\n",
    "\n",
    "# Global PerlinNoise object\n",
    "noise = PerlinNoise(octaves=10, seed=1)\n",
    "\n",
    "\n",
    "def apply_noise(easing: callable, x: np.ndarray, noise_max: float, noise_speed: float) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    Applies Perlin noise to a given easing function to create more natural variation.\n",
    "\n",
    "    Easing functions produce smooth curves that can represent animations, synthetic data,\n",
    "    or interpolation. By adding Perlin noise, we introduce **controlled randomness** \n",
    "    while keeping the general shape of the easing function.\n",
    "\n",
    "    Args:\n",
    "        easing (callable): The easing function (e.g., CubicEaseInOut).\n",
    "        x (np.ndarray): A normalized array of values from 0 to 1.\n",
    "        noise_max (float): The maximum noise influence (0 = no noise).\n",
    "        noise_speed (float): Controls noise frequency (higher = more variation).\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The noisy easing function values.\n",
    "    \"\"\"\n",
    "    noise_func = np.vectorize(lambda val: val * (1 - noise_max + noise_max * (1 + noise(val * noise_speed))))\n",
    "    return noise_func(easing(x))\n",
    "\n",
    "\n",
    "def plot_subplot(ax: plt.Axes, easing_function: callable, x: np.ndarray, noise_max: float, noise_speed: float) -> None:\n",
    "    \"\"\"\n",
    "    Plots an easing function with and without Perlin noise.\n",
    "\n",
    "    This helps visualize how Perlin noise modifies smooth transitions, making \n",
    "    easing functions more dynamic and realistic.\n",
    "\n",
    "    Args:\n",
    "        ax (plt.Axes): The subplot axis for visualization.\n",
    "        easing_function (callable): The easing function (e.g., QuinticEaseIn).\n",
    "        x (np.ndarray): A normalized array of values from 0 to 1.\n",
    "        noise_max (float): The maximum noise influence.\n",
    "        noise_speed (float): Frequency of the noise variation.\n",
    "    \"\"\"\n",
    "    easing = np.vectorize(easing_function(start=0.0, end=1.0))\n",
    "    \n",
    "    # Compute smooth and noisy curves\n",
    "    y_smooth = easing(x)\n",
    "    y_noisy = apply_noise(easing, x, noise_max, noise_speed)\n",
    "\n",
    "    ax.set_title(easing_function.__name__, fontsize=10)\n",
    "    ax.plot(x, y_smooth, label=\"No Noise\", linewidth=2)\n",
    "    ax.plot(x, y_noisy, label=\"With Perlin Noise\", linestyle=\"solid\", alpha=0.8)\n",
    "    ax.legend()\n",
    "    ax.grid(True)\n",
    "\n",
    "\n",
    "def plot_examples(noise_max: float = 0.3, noise_speed: float = 0.001) -> None:\n",
    "    \"\"\"\n",
    "    Plots multiple easing functions with and without Perlin noise.\n",
    "\n",
    "    This example is useful for **understanding** how easing functions work \n",
    "    and how Perlin noise modifies them.\n",
    "\n",
    "    Args:\n",
    "        noise_max (float): Maximum noise influence (default: 0.3).\n",
    "        noise_speed (float): Frequency of noise variation (default: 0.001).\n",
    "    \"\"\"\n",
    "    functions = [easy.CubicEaseInOut, easy.QuadEaseIn, easy.QuinticEaseIn, easy.CircularEaseIn]\n",
    "    \n",
    "    num_functions = len(functions)\n",
    "    num_cols = 2  # Fixed number of columns for better visualization\n",
    "    num_rows = math.ceil(num_functions / num_cols)\n",
    "\n",
    "    fig, axs = plt.subplots(num_rows, num_cols, figsize=(10, 6), sharex=True, sharey=True)\n",
    "    fig.suptitle(\"Examples of Easing Functions with Noise Applied\", fontsize=12)\n",
    "\n",
    "    x_values = np.linspace(0, 1, 1000)  # High-resolution curve\n",
    "\n",
    "    for i, easing_function in enumerate(functions):\n",
    "        row, col = divmod(i, num_cols)\n",
    "        plot_subplot(axs[row, col], easing_function, x_values, noise_max, noise_speed)\n",
    "\n",
    "    # Remove empty subplots if an odd number of functions\n",
    "    if num_functions % num_cols != 0:\n",
    "        fig.delaxes(axs[-1, -1])\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_interactive():\n",
    "    \"\"\"\n",
    "    Interactive widget for adjusting noise parameters and visualizing easing functions.\n",
    "\n",
    "    This allows users to explore how Perlin noise affects different easing functions.\n",
    "    \"\"\"\n",
    "    noise_max_slider = FloatSlider(value=0.3, min=0.0, max=5.0, step=0.1, description=\"Noise Max\")\n",
    "    noise_speed_slider = FloatSlider(value=2, min=0.0, max=5.0, step=0.01, description=\"Noise Speed\")\n",
    "    \n",
    "    interact(plot_examples, noise_max=noise_max_slider, noise_speed=noise_speed_slider)\n",
    "\n",
    "show_interactive()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2 - Using `easeflow` for Synthetic Data Generation (Spark)\n",
    "\n",
    "`easeflow` provides two key functions for synthetic data generation:\n",
    "\n",
    "- **`norm_df(n: int)`** â†’ Returns a DataFrame with:\n",
    "  - `id` â†’ Sequential index (0 to `n-1`)\n",
    "  - `t` â†’ Normalized values (0 to 1)\n",
    "\n",
    "- **`make_udf(easing_function, min_val, max_val)`** â†’ Creates a **PySpark UDF** that applies an easing function, optionally modified with Perlin noise.\n",
    "\n",
    "### ðŸ”¹ Generating a Normalized DataFrame\n",
    "To create a structured dataset for easing functions:\n",
    "```python\n",
    "df = norm_df(365)\n",
    "display(df)\n",
    "```\n",
    "\n",
    "Output:  \n",
    "```\n",
    "+---+------------------+  \n",
    "| id|                 t|  \n",
    "+---+------------------+  \n",
    "|  0|  0.0             |  \n",
    "|  1|  0.00274         |  \n",
    "|  2|  0.00548         |  \n",
    "|...|  ...             |  \n",
    "|364|  1.0             |  \n",
    "+---+------------------+  \n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Applying an Easing Function with Noise  \n",
    "\n",
    "We can now use make_udf to apply an easing function to this dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m display(\u001b[43mspark\u001b[49m.range(\u001b[32m10\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "display(spark.range(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append('../')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      5\u001b[39m easing_udf = make_udf(ease.QuinticEaseIn, min_val=\u001b[32m500\u001b[39m, max_val=\u001b[32m1000\u001b[39m)\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Apply the easing function with and without noise\u001b[39;00m\n\u001b[32m      8\u001b[39m df = (\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m     \u001b[43mnorm_df\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m365\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     10\u001b[39m     .withColumn(\u001b[33m\"\u001b[39m\u001b[33mv\u001b[39m\u001b[33m\"\u001b[39m, easing_udf(F.col(\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m), lit(\u001b[32m0\u001b[39m)))  \u001b[38;5;66;03m# No noise\u001b[39;00m\n\u001b[32m     11\u001b[39m     .withColumn(\u001b[33m\"\u001b[39m\u001b[33mv_noise\u001b[39m\u001b[33m\"\u001b[39m, easing_udf(F.col(\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m), lit(\u001b[32m0.3\u001b[39m)))  \u001b[38;5;66;03m# With Perlin noise\u001b[39;00m\n\u001b[32m     12\u001b[39m )\n\u001b[32m     14\u001b[39m display(df)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Git/easeflow/easeflow/easeflow.py:142\u001b[39m, in \u001b[36mnorm_df\u001b[39m\u001b[34m(n)\u001b[39m\n\u001b[32m    104\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mnorm_df\u001b[39m(n: \u001b[38;5;28mint\u001b[39m):\n\u001b[32m    105\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    106\u001b[39m \u001b[33;03m    Generates a PySpark DataFrame with two columns:\u001b[39;00m\n\u001b[32m    107\u001b[39m \u001b[33;03m        - 'id': A sequential integer index from 0 to n-1.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    140\u001b[39m \u001b[33;03m    ```\u001b[39;00m\n\u001b[32m    141\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m142\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspark\u001b[49m.range(\u001b[32m0\u001b[39m, n).withColumn(\u001b[33m\"\u001b[39m\u001b[33mt\u001b[39m\u001b[33m\"\u001b[39m, (F.col(\u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m) / (n - \u001b[32m1\u001b[39m)).cast(\u001b[33m\"\u001b[39m\u001b[33mdouble\u001b[39m\u001b[33m\"\u001b[39m))\n",
      "\u001b[31mNameError\u001b[39m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "from easeflow import make_udf, norm_df, ease\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "# Create an easing function UDF\n",
    "easing_udf = make_udf(ease.QuinticEaseIn, min_val=500, max_val=1000)\n",
    "\n",
    "# Apply the easing function with and without noise\n",
    "df = (\n",
    "    norm_df(365)\n",
    "    .withColumn(\"v\", easing_udf(F.col(\"t\"), lit(0)))  # No noise\n",
    "    .withColumn(\"v_noise\", easing_udf(F.col(\"t\"), lit(0.3)))  # With Perlin noise\n",
    ")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ðŸ”¹ Adding Time-Series Data\n",
    "\n",
    "Since norm_df() provides an id column, we can map it to a date column to simulate a time-series dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define start date\n",
    "dataset_len = 365\n",
    "start_date = datetime.today().replace(day=1) - timedelta(days=dataset_len)\n",
    "\n",
    "# Generate dataset with a date column\n",
    "df = (\n",
    "    norm_df(dataset_len)\n",
    "    .withColumn(\"date\", F.date_add(lit(start_date), F.col(\"id\").cast(\"integer\")))  # Convert `id` to a date\n",
    "    .withColumn(\"v\", easing_udf(F.col(\"t\"), lit(0)))  # No noise\n",
    "    .withColumn(\"v_noise\", easing_udf(F.col(\"t\"), lit(0.3)))  # With noise\n",
    ")\n",
    "\n",
    "display(df)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
